{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f87f2f",
   "metadata": {},
   "source": [
    "### XXXX-2022: END SEMESTER ASSESSMENT (ESA) \n",
    "## M TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n",
    "\n",
    "#### UE20CS933 - NATURAL LANGUAGE PROCESSING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d2e19",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "869655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from gensim.parsing.preprocessing import PorterStemmer, remove_stopwords\n",
    "import string \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eea2c4",
   "metadata": {},
   "source": [
    "## Section B\n",
    "### 2. Use the data.csv dataset as provided in the notebook as Pandas DataFrame and   process it as questioned below.\n",
    "\n",
    "#### Dataset \n",
    "Airline Sentiment dataset is provide as pandas dataframe. Using python NLP libraires process the dataset as questioned below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9890979d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"D:\\\\PES_MTech\\\\Sem-2\\\\NLP\\\\data.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9be4a4",
   "metadata": {},
   "source": [
    "### 2.a. Create a new Pandas DataFrame by fetching two columns 'text‚Äô and 'airline_sentiment' from data.csv.  (Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ecfc5b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   @VirginAmerica What @dhepburn said.\n",
       "1     @VirginAmerica plus you've added commercials t...\n",
       "2     @VirginAmerica I didn't today... Must mean I n...\n",
       "3     @VirginAmerica it's really aggressive to blast...\n",
       "4     @VirginAmerica and it's a really big bad thing...\n",
       "5     @VirginAmerica seriously would pay $30 a fligh...\n",
       "6     @VirginAmerica yes, nearly every time I fly VX...\n",
       "7     @VirginAmerica Really missed a prime opportuni...\n",
       "8       @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D\n",
       "9     @VirginAmerica it was amazing, and arrived an ...\n",
       "10    @VirginAmerica did you know that suicide is th...\n",
       "11    @VirginAmerica I &lt;3 pretty graphics. so muc...\n",
       "12    @VirginAmerica This is such a great deal! Alre...\n",
       "13    @VirginAmerica @virginmedia I'm flying your #f...\n",
       "14                               @VirginAmerica Thanks!\n",
       "15        @VirginAmerica SFO-PDX schedule is still MIA.\n",
       "16    @VirginAmerica So excited for my first cross c...\n",
       "17    @VirginAmerica  I flew from NYC to SFO last we...\n",
       "18                      I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç\n",
       "19    @VirginAmerica you know what would be amazingl...\n",
       "20    @VirginAmerica why are your first fares in May...\n",
       "21    @VirginAmerica I love this graphic. http://t.c...\n",
       "22    @VirginAmerica I love the hipster innovation. ...\n",
       "23    @VirginAmerica will you be making BOS&gt;LAS n...\n",
       "24    @VirginAmerica you guys messed up my seating.....\n",
       "25    @VirginAmerica status match program.  I applie...\n",
       "26    @VirginAmerica What happened 2 ur vegan food o...\n",
       "27    @VirginAmerica do you miss me? Don't worry we'...\n",
       "28    @VirginAmerica amazing to me that we can't get...\n",
       "29    @VirginAmerica LAX to EWR - Middle seat on a r...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[['text', 'airline_sentiment']]\n",
    "df.head()\n",
    "df['text'].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe69ab2",
   "metadata": {},
   "source": [
    "### 2.b. Clean the 'text' columns as questioned below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643cef6",
   "metadata": {},
   "source": [
    "#### 2.b.(i) Convert all text to lower case ( Marks- 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "146bd717-3718-4489-8276-a020e8411962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text airline_sentiment\n",
      "0                @virginamerica what @dhepburn said.           neutral\n",
      "1  @virginamerica plus you've added commercials t...          positive\n",
      "2  @virginamerica i didn't today... must mean i n...           neutral\n",
      "3  @virginamerica it's really aggressive to blast...          negative\n",
      "4  @virginamerica and it's a really big bad thing...          negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yerriswamy\\AppData\\Local\\Temp\\ipykernel_9268\\1693654608.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    lower_text = text.lower()\n",
    "    return lower_text\n",
    "\n",
    "# Apply cleaning\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d5a88-1b4c-4b1e-8e93-1121efc25da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca8b166",
   "metadata": {},
   "source": [
    "#### 2.b.(ii)  Remove the URLs (http & www) from text ( Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c5b4b022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text airline_sentiment\n",
      "0                @virginamerica what @dhepburn said.           neutral\n",
      "1  @virginamerica plus you've added commercials t...          positive\n",
      "2  @virginamerica i didn't today... must mean i n...           neutral\n",
      "3  @virginamerica it's really aggressive to blast...          negative\n",
      "4  @virginamerica and it's a really big bad thing...          negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yerriswamy\\AppData\\Local\\Temp\\ipykernel_9268\\3142843830.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.replace(r'https?://\\S+|www\\.\\S+', '', regex=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                   @virginamerica what @dhepburn said.\n",
       "1     @virginamerica plus you've added commercials t...\n",
       "2     @virginamerica i didn't today... must mean i n...\n",
       "3     @virginamerica it's really aggressive to blast...\n",
       "4     @virginamerica and it's a really big bad thing...\n",
       "5     @virginamerica seriously would pay $30 a fligh...\n",
       "6     @virginamerica yes, nearly every time i fly vx...\n",
       "7     @virginamerica really missed a prime opportuni...\n",
       "8       @virginamerica well, i didn't‚Ä¶but now i do! :-d\n",
       "9     @virginamerica it was amazing, and arrived an ...\n",
       "10    @virginamerica did you know that suicide is th...\n",
       "11    @virginamerica i &lt;3 pretty graphics. so muc...\n",
       "12    @virginamerica this is such a great deal! alre...\n",
       "13    @virginamerica @virginmedia i'm flying your #f...\n",
       "14                               @virginamerica thanks!\n",
       "15        @virginamerica sfo-pdx schedule is still mia.\n",
       "16    @virginamerica so excited for my first cross c...\n",
       "17    @virginamerica  i flew from nyc to sfo last we...\n",
       "18                      i ‚ù§Ô∏è flying @virginamerica. ‚ò∫Ô∏èüëç\n",
       "19    @virginamerica you know what would be amazingl...\n",
       "20    @virginamerica why are your first fares in may...\n",
       "21                 @virginamerica i love this graphic. \n",
       "22    @virginamerica i love the hipster innovation. ...\n",
       "23    @virginamerica will you be making bos&gt;las n...\n",
       "24    @virginamerica you guys messed up my seating.....\n",
       "25    @virginamerica status match program.  i applie...\n",
       "26    @virginamerica what happened 2 ur vegan food o...\n",
       "27    @virginamerica do you miss me? don't worry we'...\n",
       "28    @virginamerica amazing to me that we can't get...\n",
       "29    @virginamerica lax to ewr - middle seat on a r...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: regular expression for URLs  matching is 'https?://\\S+|www\\.\\S+' \n",
    "import re\n",
    "import string\n",
    "\n",
    "# Remove URLs\n",
    "df['text'] = df['text'].str.replace(r'https?://\\S+|www\\.\\S+', '', regex=True)\n",
    "\n",
    "# Show result\n",
    "print(df.head())\n",
    "df['text'].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1623fe",
   "metadata": {},
   "source": [
    "#### 2.b.(iii).  Remove stopwords from text.  ( Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2e08e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text airline_sentiment\n",
      "0                     @virginamerica @dhepburn said.           neutral\n",
      "1  @virginamerica plus added commercials experien...          positive\n",
      "2  @virginamerica today... must mean need take an...           neutral\n",
      "3  @virginamerica really aggressive blast obnoxio...          negative\n",
      "4                @virginamerica really big bad thing          negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yerriswamy\\AppData\\Local\\Temp\\ipykernel_9268\\1485177705.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_stopwords)\n"
     ]
    }
   ],
   "source": [
    "# any of nltk or gensim can be used\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    word = text.split()\n",
    "    filtered_words = [w for w in word if w.lower() not in stop]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply to the 'text' column\n",
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "\n",
    "# View cleaned text\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884da79",
   "metadata": {},
   "source": [
    "#### 2.b.(iv) Remove punctuations from text. (Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cc60d427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text airline_sentiment\n",
      "0                        virginamerica dhepburn said           neutral\n",
      "1  virginamerica plus added commercials experienc...          positive\n",
      "2  virginamerica today must mean need take anothe...           neutral\n",
      "3  virginamerica really aggressive blast obnoxiou...          negative\n",
      "4                 virginamerica really big bad thing          negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yerriswamy\\AppData\\Local\\Temp\\ipykernel_9268\\585525738.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_punctuation)\n"
     ]
    }
   ],
   "source": [
    "# Define function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Apply function to the 'text' column\n",
    "df['text'] = df['text'].apply(remove_punctuation)\n",
    "\n",
    "# Display result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac2208",
   "metadata": {},
   "source": [
    "### 2.c. Fetch the top six most frequently used words from the text corpus (Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4eccd212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('united', 4117), ('flight', 3870), ('usairways', 3039), ('americanair', 2938), ('southwestair', 2441), ('jetblue', 2256)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Combine all text into one string\n",
    "all_text = ' '.join(df['text'])\n",
    "\n",
    "# Split into words\n",
    "words = all_text.split()\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Get top 6 most common words\n",
    "top_six = word_counts.most_common(6)\n",
    "\n",
    "# Display result\n",
    "print(top_six)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b35187",
   "metadata": {},
   "source": [
    "### 3. Use the cleaned dataframe from previous section inorder to build ML model as questioned below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6706f155-4ef3-4bf8-bed8-a8b8ca43e320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7961065573770492\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.94      0.88      1889\n",
      "     neutral       0.66      0.47      0.55       580\n",
      "    positive       0.79      0.62      0.70       459\n",
      "\n",
      "    accuracy                           0.80      2928\n",
      "   macro avg       0.76      0.68      0.71      2928\n",
      "weighted avg       0.79      0.80      0.78      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split into input and output\n",
    "X = df['text']         # cleaned text column\n",
    "y = df['airline_sentiment']        # target column (replace with actual label column name)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771db55",
   "metadata": {},
   "source": [
    "### 3.a. Convert the text feature/column into numerical using Count-vectorization  (Marks-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "42f17a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of count vectorized data: (14640, 15429)\n",
      "Some feature names: ['00' '0011' '0016' '006' '0162389030167' '0162424965446' '0162431184663'\n",
      " '0167560070877' '0214' '021mbps']\n"
     ]
    }
   ],
   "source": [
    "# hint: use below count_vectorize  method definition\n",
    "#count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer with given parameters\n",
    "count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "\n",
    "# Fit and transform the 'text' column into a numerical feature matrix\n",
    "X_counts = count_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# X_counts is a sparse matrix representing the count vectors\n",
    "print(f\"Shape of count vectorized data: {X_counts.shape}\")\n",
    "\n",
    "#print('count_vectorizer : ', count_vectorizer)\n",
    "\n",
    "# Optional: To see the feature names (words)\n",
    "print(\"Some feature names:\", count_vectorizer.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afbf8dc",
   "metadata": {},
   "source": [
    "### 3.b. Convert the text  feature/column into numerical using TF-IDF (Marks-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b04f8c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF vectorized data: (14640, 15159)\n",
      "Some TF-IDF feature names: ['00' '0011' '0016' '006' '0162389030167' '0162424965446' '0162431184663'\n",
      " '0167560070877' '0214' '021mbps']\n"
     ]
    }
   ],
   "source": [
    "# hint: use below TfidfVectorizer method definition\n",
    "#tfidf_vectorizer = TfidfVectorizer(analyzer='word',stop_words='english', ngram_range=(1, 1))\n",
    "\n",
    "# Initialize TfidfVectorizer with given parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1, 1))\n",
    "\n",
    "# Fit and transform the 'text' column into TF-IDF feature matrix\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# X_tfidf is a sparse matrix representing the TF-IDF vectors\n",
    "print(f\"Shape of TF-IDF vectorized data: {X_tfidf.shape}\")\n",
    "\n",
    "# Optional: To see some feature names (words)\n",
    "print(\"Some TF-IDF feature names:\", tfidf_vectorizer.get_feature_names_out()[:10])\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d1fd5",
   "metadata": {},
   "source": [
    "### 3.c Split both Count-vectorirsed  & TF-IDF dataset into train & test set  with one fourth records being held for testing also ensure stratified sampling of traget i.e. airline_sentiment on both split ( Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b92a5-fc31-4b22-8496-cf6a18803733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed8ff379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer shapes: (10980, 14277) (3660, 14277)\n",
      "TF-IDF shapes: (10980, 14228) (3660, 14228)\n",
      "Train target distribution:\n",
      " airline_sentiment\n",
      "negative    0.626958\n",
      "neutral     0.211658\n",
      "positive    0.161384\n",
      "Name: proportion, dtype: float64\n",
      "Test target distribution:\n",
      " airline_sentiment\n",
      "negative    0.626776\n",
      "neutral     0.211749\n",
      "positive    0.161475\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# hint  use the split method : train_test_split(vectorise_dataframe,Y,stratify=Y,test_size= )\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your target variable is:\n",
    "Y = df['airline_sentiment']  # Replace if different column name\n",
    "\n",
    "# 1. Split Count Vectorized data\n",
    "X_counts_train, X_counts_test, y_counts_train, y_counts_test = train_test_split(\n",
    "    X_counts, Y, test_size=0.25, stratify=Y, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Split TF-IDF data\n",
    "X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(\n",
    "    X_tfidf, Y, test_size=0.25, stratify=Y, random_state=42\n",
    ")\n",
    "\n",
    "# Check shapes\n",
    "print(\"CountVectorizer shapes:\", X_counts_train.shape, X_counts_test.shape)\n",
    "print(\"TF-IDF shapes:\", X_tfidf_train.shape, X_tfidf_test.shape)\n",
    "print(\"Train target distribution:\\n\", y_counts_train.value_counts(normalize=True))\n",
    "print(\"Test target distribution:\\n\", y_counts_test.value_counts(normalize=True))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split count-vectorised dataset\n",
    "# 2 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tf-idf dataset\n",
    "#2 marks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7cea9",
   "metadata": {},
   "source": [
    "### 3.d Build a basic logistic regression model ( LogisticRegression(solver='liblinear')) on Count-vectorize train set and find out its accuracy on Count-vectorize test set.  ( Marks-10 = 5 -training + 5-finding accuracy )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6719994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Count-Vectorized test set: 0.7850\n"
     ]
    }
   ],
   "source": [
    "#hint:  use below LogisticRegression method\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train lr on Count-vectorize trainset\n",
    "\n",
    "# find accuracy on Count-vectorize test set \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model on Count-Vectorized train data\n",
    "lr.fit(X_counts_train, y_counts_train)\n",
    "\n",
    "# Predict on Count-Vectorized test data\n",
    "y_pred = lr.predict(X_counts_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_counts_test, y_pred)\n",
    "print(f\"Accuracy on Count-Vectorized test set: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288099d2",
   "metadata": {},
   "source": [
    "### 3.e Build a basic logistic regression model ( LogisticRegression(solver='liblinear')) on TF-IDF train set and find out its accuracy on TF-IDF test set.  Which model has better accuracy ?(  Marks-10 = 5(training) + 5 (finding accuracy) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21351b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on TF-IDF test set: 0.7645\n",
      "Count Vectorizer model accuracy: 0.7850\n",
      "Count Vectorizer model performs better.\n"
     ]
    }
   ],
   "source": [
    " # train lr on TF-IDF train set\n",
    "\n",
    "# find accuracy on TF-IDF  test set \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr_tfidf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model on TF-IDF train data\n",
    "lr_tfidf.fit(X_tfidf_train, y_tfidf_train)\n",
    "\n",
    "# Predict on TF-IDF test data\n",
    "y_tfidf_pred = lr_tfidf.predict(X_tfidf_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_tfidf = accuracy_score(y_tfidf_test, y_tfidf_pred)\n",
    "print(f\"Accuracy on TF-IDF test set: {accuracy_tfidf:.4f}\")\n",
    "\n",
    "# Compare with Count Vectorizer model accuracy (assuming accuracy variable from previous step)\n",
    "print(f\"Count Vectorizer model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Which model has better accuracy?\n",
    "if accuracy_tfidf > accuracy:\n",
    "    print(\"TF-IDF model performs better.\")\n",
    "elif accuracy_tfidf < accuracy:\n",
    "    print(\"Count Vectorizer model performs better.\")\n",
    "else:\n",
    "    print(\"Both models have the same accuracy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e913bc5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
